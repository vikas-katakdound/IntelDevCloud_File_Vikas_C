Github repository link
https://github.com/YogeshRaje/INTEL_FICE_C

Register on Intel Devcloud OneAPI
https://devcloud.intel.com/oneapi/get_started/

To download DevC++ 
https://sourceforge.net/projects/orwelldevcpp/

Invoke Intel comopler on Devcloud 
While running On Devcloud change command in file 
oneAPI_Essentials/01_oneAPI_Intro/run_simple.sh
from 
dpcpp lab/simple.cpp
to
dpcpp lab/helloworld.c

and in lab folder add file helloworld.c 
oneAPI_Essentials/01_oneAPI_Intro/lab/helloworld.c




Install and Invoke Intel optimzed complier 

Download link for Intel c c++ compiler 
https://www.intel.com/content/www/us/en/developer/articles/tool/oneapi-standalone-components.html#dpcpp-cpp


To run file using intel optimized complier 
Step1 ) Intilaize the Intel Complier 
a)Open command prompt 
>cmd 
>Cd C:\Program Files (x86)\Intel\oneAPI
> setvars.bat

b) To run c or cpp code on intel optimized complier 
>cd C:\Users\user\Desktop\mit
>dpcpp helloworld.c
>helloworld



Run program On Ubuntu Linux 
step1- open newterminal 
>nano welcome.c
write code 
save ctrl+X

>gcc welcome.c
Install gcc 
>sudo get install gcc 
>gcc welcome.c   # It will create a.out file 
check file a.out 
>dir 

run program 
>./a.out # It shows output 

To run file with our own outpout file
<gcc filename.c -o filename.out 
>gcc welcome.c -o wel.out
>dir 
>./wel.out



Install INtel's Compiler on Linux 

download comlpiler .sh file
https://www.intel.com/content/www/us/en/developer/articles/tool/oneapi-standalone-components.html#dpcpp-cpp
change mode of file 
open new terminal in Downloads
>chmod +777 filename.sh
Run .sh file 
>sh filename.sh

Intsaller will open and install intel complier 
-after installation it is saved on download comlpiler .sh file
https://www.intel.com/content/www/us/en/developer/articles/tool/oneapi-standalone-components.html#dpcpp-cpp
change mode of file 
open new terminal in Downloads
>chmod +777 filename.sh
Run .sh file 
>sh filename.sh

Intsaller will open and install intel complier 

after installation it is saved on location 
/home/yogesh/intel/oneapi
https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-dpcpp-compiler/top/get-started-on-linux.html

-open terminal in home
>cd intel/oneapi
-initialize Intel complier 
>source setvars.sh intel64 

-after initializing Intel compiler go to directory where c or c++ program (welcome.c) is saved
>cd /home/yogesh

-run program with intel complier 
>icx welcome.c -o intelwelcomedemo.out
>./intelwelcomedemo.out

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
How To see the allocated resorces 
1)Log in on Intel Devlcloud OneAPI 
2)Open Terminal 
3)check the allocated resources
>clinfo –l 
4)To get GPU
>qsub -I -l nodes=1:gpu:ppn=2 
>clinfo –l 

5)To logout 
>exit
6)To check status 
>qstat
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Day4 -

source /opt/intel/inteloneapi/setvars.sh
Task1-Run the program on Intel Devcloud 
1)Open Intel Devcloud OneAPI with your LogIn Credentials
2)Open Terminal on Intel Devcloud

2a) To invove oneapi dpcpp complier 
>source /opt/intel/inteloneapi/setvars.sh
3)Create new Folder named cprograms under oneAPI_Essentials folder
4)Upload your program into the folder named cprograms
5)Run your program eg helloworldwithtime.c using command
 >dpcpp helloworldwithtime.c -o helloworld.out
 >./helloworld.out 
 
 
 6) Request an interactive session on a DevCloud GPU node using qsub  
qsub -I -l nodes=1:gpu:ppn=2 -d .


7)create build.sh
>nano build.sh

8)save following code into build.sh and return to terminal 
#!/bin/bash
source /opt/intel/inteloneapi/setvars.sh
make clean
make all

9)create run.sh
>nano run.sh 
 
10) Save  following code into run.sh and return to terminal 
#!/bin/bash
source /opt/intel/inteloneapi/setvars.sh
dpcpp helloworldwithtime.c -o hello.out
./hello.out
make run


11)run follwoing command on terminal 
>qsub -l nodes=1:gpu:ppn=2 -d . build.sh

12)run follwoing command on terminal 
>qsub -l nodes=1:gpu:ppn=2 -d . run.sh

13)To check output run command on terminal 
>cat run.sh.oXXXX


+++++++++++++++++++++++++++++


Excersice Day4 
https://devcloud.intel.com/oneapi/documentation/base-toolkit/
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=

Day5
Task1 -Perform Intel Advisor -offload advisor for Matrix Multiplication 
open terminal on Intel Devcloud  and execute follwoing commands
1)$ mkdir day5
2)$ cd day5
3)$ git clone https://github.com/oneapi-src/oneAPI-samples.git
4)$ cd oneAPI-samples/Tools/Advisor/matrix_multiply_advisor/

5)$ cmake .
6)$ make
7)$ advixe-python $APM/collect.py advisor_project --config gen9 -- ./matrix.dpcpp
8)$ advixe-python $APM/analyze.py advisor_project --config gen9 --out-dir ./analyze
9) Check output at report.html from explorinf follwoing path
day5/oneAPI-samples/Tools/Advisor/matrix_multiply_advisor/analyze/report.html

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

